{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 87,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import torch\n",
    "from torch.utils import data\n",
    "from torch.nn.functional import normalize\n",
    "#from d2l import torch as d2l"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 88,
   "metadata": {},
   "outputs": [],
   "source": [
    "T=normalize(torch.FloatTensor(np.loadtxt(\"T.txt\")),dim=0)\n",
    "r_cross=normalize(torch.FloatTensor(np.loadtxt(\"r_cross.txt\")),dim=0)\n",
    "denorm=torch.norm(torch.FloatTensor(np.loadtxt(\"r_cross.txt\")),p=2,dim=0)\n",
    "\n",
    "class MyDataset(data.Dataset):\n",
    "    def __init__(self, feature_data, label_data):\n",
    "        self.feature_data = feature_data\n",
    "        self.label_data = label_data\n",
    "\n",
    "    def __len__(self):\n",
    "        return len(self.label_data)\n",
    "\n",
    "    def __getitem__(self, idx):\n",
    "        return self.feature_data[idx], self.label_data[idx]\n",
    "\n",
    "dataset = MyDataset(T,r_cross)\n",
    "train_size=int(0.8*len(r_cross))\n",
    "test_size=len(r_cross)-train_size\n",
    "data_train, data_test = data.random_split(dataset, [train_size, test_size])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 89,
   "metadata": {},
   "outputs": [],
   "source": [
    "batch_size = 40\n",
    "data_iter = data.DataLoader(data_train, batch_size, shuffle=True)\n",
    "test_data_iter = data.DataLoader(data_test, batch_size, shuffle=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 90,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[tensor([[-0.0683, -0.0669, -0.0688,  ..., -0.0702, -0.0715, -0.0724],\n",
       "         [-0.0731, -0.0757, -0.0749,  ..., -0.0747, -0.0729, -0.0736],\n",
       "         [-0.0704, -0.0681, -0.0641,  ..., -0.0650, -0.0670, -0.0638],\n",
       "         ...,\n",
       "         [-0.0722, -0.0730, -0.0721,  ..., -0.0729, -0.0724, -0.0743],\n",
       "         [-0.0706, -0.0681, -0.0665,  ..., -0.0667, -0.0681, -0.0644],\n",
       "         [-0.0711, -0.0704, -0.0705,  ..., -0.0721, -0.0721, -0.0740]]),\n",
       " tensor([0.0929, 0.0667, 0.0402, 0.0674, 0.0882, 0.0375, 0.0368, 0.0817, 0.0439,\n",
       "         0.0923, 0.0500, 0.0766, 0.0623, 0.0984, 0.0793, 0.0419, 0.0838, 0.0746,\n",
       "         0.0616, 0.0538, 0.0579, 0.0449, 0.1008, 0.0381, 0.0661, 0.0977, 0.0780,\n",
       "         0.0572, 0.0436, 0.0718, 0.0895, 0.0851, 0.0940, 0.0344, 0.0497, 0.0412,\n",
       "         0.0347, 0.0773, 0.0422, 0.0848])]"
      ]
     },
     "execution_count": 90,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "next(iter(data_iter))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 91,
   "metadata": {},
   "outputs": [],
   "source": [
    "net=torch.nn.Sequential(torch.nn.Linear(128,128),torch.nn.ReLU(),torch.nn.Linear(128,128),torch.nn.ReLU(),torch.nn.Linear(128,1))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 96,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch 100, loss 0.000036\n",
      "test_loss 0.000030\n",
      "epoch 100, loss 0.000008\n",
      "test_loss 0.000007\n",
      "epoch 100, loss 0.000060\n",
      "test_loss 0.000068\n",
      "epoch 100, loss 0.000042\n",
      "test_loss 0.000042\n",
      "epoch 100, loss 0.000050\n",
      "test_loss 0.000036\n",
      "epoch 100, loss 0.000024\n",
      "test_loss 0.000019\n",
      "epoch 100, loss 0.000006\n",
      "test_loss 0.000005\n",
      "epoch 100, loss 0.000038\n",
      "test_loss 0.000038\n",
      "epoch 100, loss 0.000006\n",
      "test_loss 0.000006\n",
      "epoch 100, loss 0.000020\n",
      "test_loss 0.000020\n",
      "epoch 100, loss 0.000010\n",
      "test_loss 0.000007\n",
      "epoch 100, loss 0.000027\n",
      "test_loss 0.000027\n",
      "epoch 100, loss 0.000012\n",
      "test_loss 0.000011\n",
      "epoch 100, loss 0.000011\n",
      "test_loss 0.000010\n",
      "epoch 100, loss 0.000019\n",
      "test_loss 0.000014\n",
      "epoch 100, loss 0.000007\n",
      "test_loss 0.000008\n",
      "epoch 100, loss 0.000086\n",
      "test_loss 0.000075\n",
      "epoch 100, loss 0.000019\n",
      "test_loss 0.000020\n",
      "epoch 100, loss 0.000063\n",
      "test_loss 0.000047\n",
      "epoch 100, loss 0.000019\n",
      "test_loss 0.000021\n",
      "epoch 100, loss 0.000052\n",
      "test_loss 0.000055\n",
      "epoch 100, loss 0.000011\n",
      "test_loss 0.000012\n",
      "epoch 100, loss 0.000033\n",
      "test_loss 0.000019\n",
      "epoch 100, loss 0.000018\n",
      "test_loss 0.000020\n",
      "epoch 100, loss 0.000058\n",
      "test_loss 0.000052\n",
      "epoch 100, loss 0.000008\n",
      "test_loss 0.000005\n",
      "epoch 100, loss 0.000012\n",
      "test_loss 0.000012\n",
      "epoch 63, loss 0.000004\n",
      "test_loss 0.000003\n",
      "tensor([1.6832, 2.2680, 1.8462, 2.0790, 1.6628, 2.2250, 2.7961, 1.3232, 2.1538,\n",
      "        2.7608, 1.3479, 2.7875, 2.7363, 1.2925, 1.6751, 2.5081, 1.2341, 2.1622,\n",
      "        2.5576, 1.4676, 2.8344, 2.1194, 2.1382, 1.5796, 1.9003, 1.9659, 2.7186,\n",
      "        1.4733, 1.7289, 1.3704, 1.3663, 2.8293, 2.5720, 1.2350, 1.7970, 2.8178,\n",
      "        1.0258, 1.6471, 2.3802, 2.5358], grad_fn=<MulBackward0>)\n",
      "tensor([1.7700, 2.2600, 1.8900, 2.1300, 1.6500, 2.2400, 2.7800, 1.2500, 2.2000,\n",
      "        2.7500, 1.2600, 2.9200, 2.6800, 1.2000, 1.7100, 2.5100, 1.2200, 2.1700,\n",
      "        2.5300, 1.5000, 2.8800, 2.1400, 2.1000, 1.6600, 1.9300, 2.0000, 2.7200,\n",
      "        1.5200, 1.7600, 1.3500, 1.3000, 2.9700, 2.5600, 1.1300, 1.8500, 2.8400,\n",
      "        1.0600, 1.6700, 2.3600, 2.5400])\n"
     ]
    }
   ],
   "source": [
    "loss = torch.nn.MSELoss()\n",
    "l = loss(net(T).squeeze(-1), r_cross)\n",
    "need_l=4e-6\n",
    "T_test, r_cross_test=next(iter(test_data_iter))\n",
    "l_test = loss(net(T_test).squeeze(-1), r_cross_test)\n",
    "while l_test>need_l:\n",
    "\n",
    "    for i in (0,2,4):\n",
    "        net[i].weight.data.normal_(0, 0.15)\n",
    "        net[i].bias.data.fill_(0)\n",
    "\n",
    "    trainer = torch.optim.SGD(net.parameters(), lr=0.03)\n",
    "\n",
    "    num_epochs = 100\n",
    "    for epoch in range(num_epochs):\n",
    "        for X, y in data_iter:\n",
    "            l = loss(net(X).squeeze(-1) ,y)\n",
    "            trainer.zero_grad()\n",
    "            l.backward()\n",
    "            trainer.step()\n",
    "        l = loss(net(T).squeeze(-1), r_cross)\n",
    "        if l <= need_l:\n",
    "            break\n",
    "    print(f'epoch {epoch + 1}, loss {l:f}')\n",
    "    l_test = loss(net(T_test).squeeze(-1), r_cross_test)\n",
    "    print(f\"test_loss {l_test:f}\")\n",
    "\n",
    "\n",
    "\n",
    "print(net(T_test).squeeze(-1)*denorm*1e4)\n",
    "print(r_cross_test*denorm*1e4)\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "py368",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
