{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 97,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import torch\n",
    "from torch.utils import data\n",
    "from torch.nn.functional import normalize\n",
    "#from d2l import torch as d2l"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 98,
   "metadata": {},
   "outputs": [],
   "source": [
    "T=normalize(torch.FloatTensor(np.loadtxt(\"T.txt\")),dim=0)\n",
    "r_cross=normalize(torch.FloatTensor(np.loadtxt(\"r_cross.txt\")),dim=0)\n",
    "denorm=torch.norm(torch.FloatTensor(np.loadtxt(\"r_cross.txt\")),p=2,dim=0)\n",
    "\n",
    "class MyDataset(data.Dataset):\n",
    "    def __init__(self, feature_data, label_data):\n",
    "        self.feature_data = feature_data\n",
    "        self.label_data = label_data\n",
    "\n",
    "    def __len__(self):\n",
    "        return len(self.label_data)\n",
    "\n",
    "    def __getitem__(self, idx):\n",
    "        return self.feature_data[idx], self.label_data[idx]\n",
    "\n",
    "dataset = MyDataset(T,r_cross)\n",
    "train_size=int(0.8*len(r_cross))\n",
    "test_size=len(r_cross)-train_size\n",
    "\n",
    "data_train, data_test = data.random_split(dataset, [train_size, test_size])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 99,
   "metadata": {},
   "outputs": [],
   "source": [
    "batch_size = 80\n",
    "data_iter = data.DataLoader(data_train, batch_size, shuffle=True)\n",
    "test_data_iter = data.DataLoader(data_test, batch_size, shuffle=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 100,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[tensor([[-0.0708, -0.0684, -0.0671,  ..., -0.0652, -0.0666, -0.0638],\n",
       "         [-0.0719, -0.0715, -0.0710,  ..., -0.0718, -0.0719, -0.0740],\n",
       "         [-0.0727, -0.0739, -0.0730,  ..., -0.0727, -0.0723, -0.0750],\n",
       "         ...,\n",
       "         [-0.0721, -0.0719, -0.0715,  ..., -0.0724, -0.0726, -0.0750],\n",
       "         [-0.0720, -0.0736, -0.0748,  ..., -0.0721, -0.0708, -0.0701],\n",
       "         [-0.0709, -0.0701, -0.0702,  ..., -0.0712, -0.0719, -0.0740]]),\n",
       " tensor([0.0429, 0.0827, 0.0759, 0.0643, 0.0947, 0.0752, 0.0548, 0.0749, 0.0347,\n",
       "         0.0449, 0.0729, 0.0504, 0.0732, 0.0368, 0.0456, 0.0507, 0.0562, 0.0885,\n",
       "         0.0609, 0.0858, 0.0402, 0.0555, 0.0650, 0.0640, 0.0688, 0.0681, 0.0538,\n",
       "         0.0460, 0.0912, 0.0909, 0.0817, 0.0701, 0.0569, 0.0831, 0.0977, 0.0735,\n",
       "         0.0746, 0.0552, 0.0769, 0.0783, 0.0453, 0.0902, 0.0780, 0.1018, 0.0725,\n",
       "         0.0432, 0.0623, 0.0483, 0.0664, 0.0357, 0.0923, 0.0756, 0.0511, 0.0929,\n",
       "         0.0586, 0.0824, 0.0684, 0.0994, 0.0626, 0.0678, 0.0381, 0.0606, 0.0933,\n",
       "         0.0861, 0.0882, 0.0674, 0.0446, 0.0940, 0.0616, 0.0466, 0.0630, 0.0596,\n",
       "         0.0473, 0.0620, 0.0705, 0.0957, 0.0603, 0.0814, 0.0579, 0.0851])]"
      ]
     },
     "execution_count": 100,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "next(iter(data_iter))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 101,
   "metadata": {},
   "outputs": [],
   "source": [
    "net=torch.nn.Sequential(torch.nn.Linear(128,128),torch.nn.ReLU(),torch.nn.Linear(128,128),torch.nn.ReLU(),torch.nn.Linear(128,1))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 111,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch 200, loss 0.000010\n",
      "test_loss 0.000010\n",
      "epoch 200, loss 0.000048\n",
      "test_loss 0.000049\n",
      "epoch 200, loss 0.000009\n",
      "test_loss 0.000011\n",
      "epoch 200, loss 0.000012\n",
      "test_loss 0.000013\n",
      "epoch 200, loss 0.000012\n",
      "test_loss 0.000012\n",
      "epoch 200, loss 0.000011\n",
      "test_loss 0.000012\n",
      "epoch 200, loss 0.000016\n",
      "test_loss 0.000019\n",
      "epoch 200, loss 0.000052\n",
      "test_loss 0.000055\n",
      "epoch 200, loss 0.000044\n",
      "test_loss 0.000045\n",
      "epoch 200, loss 0.000025\n",
      "test_loss 0.000028\n",
      "epoch 200, loss 0.000012\n",
      "test_loss 0.000012\n",
      "epoch 200, loss 0.000018\n",
      "test_loss 0.000021\n",
      "epoch 200, loss 0.000028\n",
      "test_loss 0.000032\n",
      "epoch 200, loss 0.000119\n",
      "test_loss 0.000127\n",
      "epoch 118, loss 0.000006\n",
      "test_loss 0.000007\n",
      "epoch 200, loss 0.000011\n",
      "test_loss 0.000011\n",
      "epoch 200, loss 0.000042\n",
      "test_loss 0.000040\n",
      "epoch 200, loss 0.000015\n",
      "test_loss 0.000017\n",
      "epoch 87, loss 0.000006\n",
      "test_loss 0.000007\n",
      "epoch 54, loss 0.000006\n",
      "test_loss 0.000008\n",
      "epoch 200, loss 0.000062\n",
      "test_loss 0.000069\n",
      "epoch 200, loss 0.000011\n",
      "test_loss 0.000013\n",
      "epoch 200, loss 0.000123\n",
      "test_loss 0.000123\n",
      "epoch 200, loss 0.000008\n",
      "test_loss 0.000012\n",
      "epoch 200, loss 0.000035\n",
      "test_loss 0.000038\n",
      "epoch 200, loss 0.000023\n",
      "test_loss 0.000029\n",
      "epoch 200, loss 0.000044\n",
      "test_loss 0.000053\n",
      "epoch 200, loss 0.000007\n",
      "test_loss 0.000010\n",
      "epoch 200, loss 0.000044\n",
      "test_loss 0.000051\n",
      "epoch 103, loss 0.000006\n",
      "test_loss 0.000005\n",
      "tensor([0.9602, 1.3427, 1.2945, 1.5374, 1.4116, 2.3568, 2.9383, 2.5176, 1.5691,\n",
      "        2.8238, 1.2810, 2.4480, 2.2886, 2.3262, 1.8939, 2.2690, 2.6558, 1.5617,\n",
      "        2.2568, 2.6850, 2.6415, 1.6645, 1.4706, 1.2673, 2.2415, 2.9284, 2.0015,\n",
      "        1.3375, 1.2579, 2.7768, 2.8909, 2.9029, 1.9004, 1.3725, 1.8415, 1.9150,\n",
      "        1.8673, 1.6835, 1.6150, 2.6335], grad_fn=<MulBackward0>)\n",
      "tensor([1.0000, 1.3800, 1.1400, 1.5700, 1.4400, 2.3300, 2.9700, 2.4700, 1.5900,\n",
      "        2.8300, 1.2900, 2.4500, 2.3200, 2.3400, 1.9700, 2.2800, 2.5700, 1.5400,\n",
      "        2.3100, 2.6100, 2.5600, 1.7300, 1.5100, 1.1700, 2.2700, 2.8400, 2.0800,\n",
      "        1.1900, 1.1000, 2.7000, 2.8900, 2.9800, 1.9600, 1.4000, 1.9000, 2.0400,\n",
      "        1.9400, 1.7100, 1.6600, 2.5800])\n"
     ]
    }
   ],
   "source": [
    "loss = torch.nn.MSELoss()\n",
    "l = loss(net(T).squeeze(-1), r_cross)\n",
    "need_l=6e-6\n",
    "T_test, r_cross_test=next(iter(test_data_iter))\n",
    "l_test = loss(net(T_test).squeeze(-1), r_cross_test)\n",
    "\n",
    "while l_test>need_l:\n",
    "\n",
    "    for i in (0,2,4):\n",
    "        net[i].weight.data.normal_(0, 0.15)\n",
    "        net[i].bias.data.fill_(0)\n",
    "\n",
    "    trainer = torch.optim.SGD(net.parameters(), lr=0.03)\n",
    "\n",
    "    num_epochs = 200\n",
    "    for epoch in range(num_epochs):\n",
    "        for X, y in data_iter:\n",
    "            l = loss(net(X).squeeze(-1) ,y)\n",
    "            trainer.zero_grad()\n",
    "            l.backward()\n",
    "            trainer.step()\n",
    "        l = loss(net(T).squeeze(-1), r_cross)\n",
    "        if l <= need_l:\n",
    "            break\n",
    "    print(f'epoch {epoch + 1}, loss {l:f}')\n",
    "    l_test = loss(net(T_test).squeeze(-1), r_cross_test)\n",
    "    print(f\"test_loss {l_test:f}\")\n",
    "\n",
    "print(net(T_test).squeeze(-1)*denorm*1e4)\n",
    "print(r_cross_test*denorm*1e4)\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "py368",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
